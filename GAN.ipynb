{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxmteZYymEGT",
        "outputId": "4682bd67-d197-4e33-d9b9-5be3907f6d43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCTAQjrunLlE",
        "outputId": "7d69b850-4ad1-48c9-e97e-7de879a26474"
      },
      "source": [
        "%cd ../x64\n",
        "%ls "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CSC413/x64\n",
            "Imagenet64_train_part1.zip  Imagenet64_train_part2.zip  Imagenet64_val.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8tOndz6lL70"
      },
      "source": [
        "import zipfile\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yey8pcCzzOQi"
      },
      "source": [
        "from os import walk\n",
        "_, _, filenames = next(walk(\".\"))\n",
        "\n",
        "for filename in filenames: \n",
        "  print(filename)\n",
        "  with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEzBqrqD1a57"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import pickle\n",
        "import numpy as np \n",
        "import torch.optim"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpPBcP5m_awL"
      },
      "source": [
        "class generator (torch.nn.Module):\n",
        "\n",
        "  def __init__( self):\n",
        "    super(generator, self).__init__()\n",
        "    self.Conv1 = torch.nn.Conv2d(3, 64, 9)\n",
        "    self.BConv1 = torch.nn.Conv2d(64, 64, 3)\n",
        "    self.BConv2 = torch.nn.Conv2d(64, 64, 3)\n",
        "    self.BbatchNorm = torch.nn.BatchNorm2d(64)\n",
        "    self.Conv2 = torch.nn.Conv2d(64, 64, 3)\n",
        "    self.Conv3 = torch.nn.Conv2d(64, 256, 3)\n",
        "    self.Conv4 = torch.nn.Conv2d(64, 256, 3)\n",
        "    self.ConvFinal = torch.nn.Conv2d(256, 3, 9)\n",
        "    self.PixelShuffle = torch.nn.PixelShuffle(upscale_factor=2)\n",
        "    self.PreLU = torch.nn.PReLU();\n",
        "    self.BatchNorm = torch.nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "\n",
        "  def forward(self, x ):\n",
        "    x = self.Conv1(x)\n",
        "    x = self.PreLU(x)\n",
        "    x1 = x.detach().clone()\n",
        "    x2 = x.detach().clone()\n",
        "\n",
        "    for i in range(4):\n",
        "      x  = self.BConv1(x)\n",
        "      x = self.BatchNorm(x)\n",
        "      x = self.PreLU(x)\n",
        "      x = self.BConv2(x)\n",
        "      x = self.BatchNorm(x)\n",
        "      x = x + x1 \n",
        "      x1 = x.detach().clone()\n",
        "\n",
        "    x = self.Conv2(x)\n",
        "    x = self.BatchNorm(x)\n",
        "    x = x + x2 \n",
        "\n",
        "    x = self.Conv3(x)\n",
        "    x = self.PixelShuffle(x)\n",
        "    x = self.PreLU(x)\n",
        "    \n",
        "    x = self.Conv4(x)\n",
        "    x = self.PixelShuffle(x)\n",
        "    x = self.PreLU(x)\n",
        "\n",
        "    x = self.ConvFinal(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYFT-UojGC8Q"
      },
      "source": [
        "class discrimator (torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(discrimator, self).__init__()\n",
        "    self.Conv1 = torch.nn.Conv2d(3, 64, 3)\n",
        "    self.Conv2 = torch.nn.Conv2d(64, 64, 3, stride=2)\n",
        "    self.BatchNorm2 = torch.nn.BatchNorm2d(num_features=64)\n",
        "    self.Conv3 = torch.nn.Conv2d(64, 128, 3)\n",
        "    self.BatchNorm3 = torch.nn.BatchNorm2d(num_features=128)\n",
        "    self.Conv4 = torch.nn.Conv2d(1283, 128, 3, 2)\n",
        "    self.BatchNorm4 = torch.nn.BatchNorm2d(num_features=128)\n",
        "    self.Conv5 = torch.nn.Conv2d(128, 256, kernel_size=3)\n",
        "    self.BatchNorm5 = torch.nn.BatchNorm2d(num_features=256)\n",
        "    self.Conv6 = torch.nn.Conv2d(256, 256, kernel_size=3,stride=2)\n",
        "    self.BatchNorm6 = torch.nn.BatchNorm2d(num_features=256)\n",
        "    self.Conv7 = torch.nn.Conv2d(256, 512, kernel_size=3)\n",
        "    self.BatchNorm7 = torch.nn.BatchNorm2d(num_features=512)\n",
        "    self.Conv8 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=2)\n",
        "    self.BatchNorm8 = torch.nn.BatchNorm2d(num_features=512)\n",
        "\n",
        "    self.hidden = torch.nn.Linear(in_features=131072, out_features=1024)\n",
        "    self.final_classifier = torch.nn.Linear(in_features=1024, out_features=1)\n",
        "    self.leakyReLU = torch.nn.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "  def forward(self, x ):\n",
        "    x = self.leakyReLU(self.Conv1(x))\n",
        "    x = self.leakyReLU(self.BatchNorm2(self.Conv2(x)))\n",
        "    x = self.leakyReLU(self.BatchNorm3(self.Conv3(x)))\n",
        "    x = self.leakyReLU(self.BatchNorm4(self.Conv4(x)))\n",
        "    x = self.leakyReLU(self.BatchNorm5(self.Conv5(x)))\n",
        "    x = self.leakyReLU(self.BatchNorm6(self.Conv6(x)))\n",
        "    x = self.leakyReLU(self.BatchNorm7(self.Conv7(x)))\n",
        "    x = self.leakyReLU(self.BatchNorm8(self.Conv8(x)))\n",
        "    x = x.reshape(-1)\n",
        "    x = self.leakyReLU(self.hidden(x))\n",
        "    return torch.sigmoid(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlzccsRnRqgL"
      },
      "source": [
        "class vgg_loss ():\n",
        "\n",
        "  def __init__(self):\n",
        "    super(vgg_loss, self).__init__()\n",
        "    vgg = torchvision.models.vgg19()\n",
        "    vgg = vgg.features\n",
        "\n",
        "    # Freeze all vgg layers \n",
        "    for param in vgg.parameters():\n",
        "      param.requires_grad = False \n",
        "    \n",
        "    self.vgg = vgg[:27] \n",
        "    self.MSE = torch.nn.MSELoss()\n",
        "\n",
        "  def __call__(self, input, target ):\n",
        "    vgg_input = self.vgg(input)\n",
        "    vgg_target = self.vgg(target)\n",
        "    return self.MSE(vgg_input, vgg_target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQJ4ORUw-NtH",
        "outputId": "af52f31f-da1a-4b6f-8da3-ca566bd1f5f4"
      },
      "source": [
        "disc = discrimator()\n",
        "gen = generator()\n",
        "disc_params = sum(p.numel() for p in disc.parameters())\n",
        "gen_params = sum(p.numel() for p in gen.parameters())\n",
        "print(disc_params)\n",
        "print(gen_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "140239425\n",
            "484292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHMIV_cxTZl2"
      },
      "source": [
        "loss = vgg_loss()\n",
        "print(loss.vgg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySLjI6M1zKQK"
      },
      "source": [
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo)\n",
        "    return dict "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOL2ESHyynZ-"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/CSC413'\n",
        "\n",
        "def get_images_x64(batch):\n",
        "  filename = data_dir + \"/x64/\" + batch \n",
        "  d = unpickle(filename)\n",
        "  x = d['data']\n",
        "  x = np.dstack((x[:, :4096], x[:, 4096:8192], x[:, 8192:]))\n",
        "  x = x.reshape((x.shape[0], 64, 64, 3))\n",
        "  return x\n",
        "\n",
        "\n",
        "def get_images_x16(filename):\n",
        "  filename = data_dir + \"/x16/\" + batch \n",
        "  d = unpickle(filename)\n",
        "  x = d['data']\n",
        "  x = np.dstack((x[:, :256], x[:, 256:512], x[:, 512:]))\n",
        "  x = x.reshape((x.shape[0], 16, 16, 3))\n",
        "  return x  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk1VMxnf38kh",
        "outputId": "363c04dd-6373-4db2-b18f-c2467789d2fe"
      },
      "source": [
        "%ls /content/drive/MyDrive/CSC413/x64\n",
        "\n",
        "batch = 'train_data_batch_2'\n",
        "X = get_images_x16( batch )\n",
        "Y = get_images_x64( batch )"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imagenet64_train_part1.zip  train_data_batch_2  train_data_batch_7\n",
            "Imagenet64_train_part2.zip  train_data_batch_3  train_data_batch_8\n",
            "Imagenet64_val.zip          train_data_batch_4  train_data_batch_9\n",
            "train_data_batch_1          train_data_batch_5  val_data\n",
            "train_data_batch_10         train_data_batch_6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ABUf6vv4c0u"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig=plt.figure(figsize=(1, 2))\n",
        "plt.imshow(X[4, :])\n",
        "plt.imshow(Y[4, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfjpXNYyAgcY"
      },
      "source": [
        "def gan_checkpoint(iteration, G, D, opts):\n",
        "    \"\"\"Saves the parameters of the generator G and discriminator D.\n",
        "    \"\"\"\n",
        "    G_path = os.path.join(opts.checkpoint_dir, 'G.pkl')\n",
        "    D_path = os.path.join(opts.checkpoint_dir, 'D.pkl')\n",
        "    torch.save(G.state_dict(), G_path)\n",
        "    torch.save(D.state_dict(), D_path)\n",
        "\n",
        "def load_checkpoint(opts):\n",
        "    \"\"\"Loads the generator and discriminator models from checkpoints.\n",
        "    \"\"\"\n",
        "    G_path = os.path.join(opts.load, 'G.pkl')\n",
        "    D_path = os.path.join(opts.load, 'D_.pkl')\n",
        "\n",
        "    G = DCGenerator(noise_size=opts.noise_size, conv_dim=opts.g_conv_dim, spectral_norm=opts.spectral_norm)\n",
        "    D = DCDiscriminator(conv_dim=opts.d_conv_dim)\n",
        "\n",
        "    G.load_state_dict(torch.load(G_path, map_location=lambda storage, loc: storage))\n",
        "    D.load_state_dict(torch.load(D_path, map_location=lambda storage, loc: storage))\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        G.cuda()\n",
        "        D.cuda()\n",
        "        print('Models moved to GPU.')\n",
        "\n",
        "    return G, D\n",
        "\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOGoKyuSACfx"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "CREDITS: CSC413 PA4 DCGAN\n",
        "\n",
        "\"\"\"\n",
        "def gan_training_loop(dataloader, test_dataloader, opts):\n",
        "    \"\"\"Runs the training loop.\n",
        "        * Saves checkpoint every opts.checkpoint_every iterations\n",
        "        * Saves generated samples every opts.sample_every iterations\n",
        "    \"\"\"\n",
        "\n",
        "    # Create generators and discriminators\n",
        "    G = generator()\n",
        "    D = discriminator()\n",
        "\n",
        "    g_params = G.parameters()  # Get generator parameters\n",
        "    d_params = D.parameters()  # Get discriminator parameters\n",
        "\n",
        "    # Create optimizers for the generators and discriminators\n",
        "    g_optimizer = optim.Adam(g_params, opts.lr, [opts.beta1, opts.beta2])\n",
        "    d_optimizer = optim.Adam(d_params, opts.lr * 2., [opts.beta1, opts.beta2])\n",
        "\n",
        "    train_iter = iter(dataloader)\n",
        "    test_iter = iter(test_dataloader)\n",
        "\n",
        "    # Get some fixed data from domains X and Y for sampling. These are images that are held\n",
        "    # constant throughout training, that allow us to inspect the model's performance.\n",
        "    fixed_noise = sample_noise(100, opts.noise_size)  # # 100 x noise_size x 1 x 1\n",
        "\n",
        "    iter_per_epoch = len(train_iter)\n",
        "    total_train_iters = opts.train_iters\n",
        "\n",
        " \n",
        "    # adversarial_loss = torch.nn.BCEWithLogitsLoss()\n",
        "    gp_weight = 1\n",
        "\n",
        "    losses ={}\n",
        "    losses['iteration'] = []\n",
        "    losses['D_real_loss'] = []\n",
        "    losses['D_fake_loss'] = []\n",
        "    losses['G_loss'] = []\n",
        "\n",
        "\n",
        "    try:\n",
        "        for iteration in range(1, opts.train_iters + 1):\n",
        "\n",
        "            # Reset data_iter for each epoch\n",
        "            if iteration % iter_per_epoch == 0:\n",
        "                train_iter = iter(dataloader)\n",
        "\n",
        "            real_images, real_labels = train_iter.next()\n",
        "            real_images, real_labels = to_var(real_images), to_var(real_labels).long().squeeze()\n",
        "\n",
        "            for d_i in range(opts.d_train_iters):\n",
        "                d_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "                # TODO modify to the new training loss\n",
        "                m_rec = 1 /  (2 * real_images.shape[0])\n",
        "                D_1 = (D(real_images) -1 )\n",
        "                D_1 = D_1 ** 2 \n",
        "                D_real_loss =  m_rec  * torch.sum(D_1) \n",
        "                noise = sample_noise(real_images.shape[0], opts.noise_size)\n",
        "                fake_images = G(noise)\n",
        "                D_fake_loss = D(fake_images) ** 2 \n",
        "                D_fake_loss = m_rec * torch.sum(D_fake_loss)\n",
        "          \n",
        "\n",
        "                # ---- Gradient Penalty ----\n",
        "                if opts.gradient_penalty:\n",
        "                    alpha = torch.rand(real_images.shape[0], 1, 1, 1)\n",
        "                    alpha = alpha.expand_as(real_images).cuda()\n",
        "                    interp_images = Variable(alpha * real_images.data + (1 - alpha) * fake_images.data, requires_grad=True).cuda()\n",
        "                    D_interp_output = D(interp_images)\n",
        "\n",
        "                    gradients = torch.autograd.grad(outputs=D_interp_output, inputs=interp_images,\n",
        "                                                    grad_outputs=torch.ones(D_interp_output.size()).cuda(),\n",
        "                                                    create_graph=True, retain_graph=True)[0]\n",
        "                    gradients = gradients.view(real_images.shape[0], -1)\n",
        "                    gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
        "\n",
        "                    gp = gp_weight * gradients_norm.mean()\n",
        "                else:\n",
        "                    gp = 0.0\n",
        "\n",
        "                D_total_loss = D_fake_loss + D_real_loss + gp \n",
        "                D_total_loss.backward()\n",
        "                d_optimizer.step()\n",
        "\n",
        "\n",
        "            g_optimizer.zero_grad()\n",
        "            noise = sample_noise(real_images.shape[0], opts.noise_size)\n",
        "            fake_images = G(noise)\n",
        "            G_loss =  torch.sum( (D(fake_images) -1 ) ** 2) \n",
        "            G_loss = (1 / real_images.shape[0]) * G_loss \n",
        "\n",
        "            G_loss.backward()\n",
        "            g_optimizer.step()\n",
        "            \n",
        "            if iteration % opts.log_step == 0:\n",
        "                losses['iteration'].append(iteration)\n",
        "                losses['D_real_loss'].append(D_real_loss.item())\n",
        "                losses['D_fake_loss'].append(D_fake_loss.item())\n",
        "                losses['G_loss'].append(G_loss.item())\n",
        "                print('Iteration [{:4d}/{:4d}] | D_real_loss: {:6.4f} | D_fake_loss: {:6.4f} | G_loss: {:6.4f}'.format(\n",
        "                    iteration, total_train_iters, D_real_loss.item(), D_fake_loss.item(), G_loss.item()))\n",
        "\n",
        "            # Save the generated samples\n",
        "            # if iteration % opts.sample_every == 0:\n",
        "            #     gan_save_samples(G, fixed_noise, iteration, opts)\n",
        "\n",
        "            # Save the model parameters\n",
        "            if iteration % opts.checkpoint_every == 0:\n",
        "                gan_checkpoint(iteration, G, D, opts)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('Exiting early from training.')\n",
        "        return G, D\n",
        "\n",
        "\n",
        "    return G, D"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}