{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN x128.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxmteZYymEGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f64bc4f1-6fb0-4d74-bc05-4c25abd0a378"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEzBqrqD1a57"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import pickle\n",
        "import numpy as np \n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from pathlib import Path\n",
        "import fnmatch\n",
        "\n",
        "import torch.optim\n",
        "from scipy.io.idl import AttrDict\n",
        "\n",
        "from PIL import Image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhG73ITGWndz"
      },
      "source": [
        "# IMAGE UNZIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8tOndz6lL70"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "from os import walk\n",
        "\n",
        "extract_x64 = False \n",
        "\n",
        "if extract_x64: \n",
        "  _, _, filenames = next(walk(\".\"))\n",
        "\n",
        "  for filename in filenames: \n",
        "    print(filename)\n",
        "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "      zip_ref.extractall(\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yey8pcCzzOQi"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "extract_x128 = False \n",
        "if extract_x128: \n",
        "  %cd /content/\n",
        "  %mkdir flickr\n",
        "  %mkdir scrape \n",
        "\n",
        "  path = \"/content/drive/MyDrive/CSC413/flickr/flickr.zip\"\n",
        "  with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(\"/content/flickr\")\n",
        "  \n",
        "  path = \"/content/drive/MyDrive/CSC413/scrape/scrape.zip\"\n",
        "  with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(\"/content/scrape\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aThIZDMBXMSs"
      },
      "source": [
        "# ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpPBcP5m_awL"
      },
      "source": [
        "class generator (torch.nn.Module):\n",
        "\n",
        "  def __init__( self):\n",
        "    super(generator, self).__init__()\n",
        "    self.Conv1 = torch.nn.Conv2d(3, 64, 9, padding=4)\n",
        "\n",
        "    self.residual_block = torch.nn.Sequential()\n",
        "    for i in range(16):\n",
        "      self.residual_block = torch.nn.Sequential(*list(self.residual_block) + [ResidualBlock()])\n",
        "\n",
        "    self.Conv2 = torch.nn.Conv2d(64, 64, 3, padding=1 )\n",
        "    self.Conv3 = torch.nn.Conv2d(64, 256, 3, padding=1 )\n",
        "    self.Conv4 = torch.nn.Conv2d(64, 256, 3, padding=1 )\n",
        "    self.ConvFinal = torch.nn.Conv2d(64, 3, 9, padding=4)\n",
        "    self.PixelShuffle = torch.nn.PixelShuffle(upscale_factor=2)\n",
        "    self.PreLU = torch.nn.PReLU();\n",
        "    self.BatchNorm = torch.nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "\n",
        "  def forward(self, x ):\n",
        "\n",
        "    x = self.Conv1(x)\n",
        "    x = self.PreLU(x)\n",
        "    \n",
        "    x1 = x\n",
        "    x2 = x\n",
        "\n",
        "    self.residual_block(x1)\n",
        "\n",
        "    x = self.Conv2(x)\n",
        "    x = self.BatchNorm(x)\n",
        "    x = x + x2 \n",
        "\n",
        "    x = self.Conv3(x)\n",
        "    x = self.PixelShuffle(x)\n",
        "    x = self.PreLU(x)\n",
        "    \n",
        "    x = self.Conv4(x)\n",
        "    x = self.PixelShuffle(x)\n",
        "    x = self.PreLU(x)\n",
        "\n",
        "    x = self.ConvFinal(x)\n",
        "    return x \n",
        "\n",
        "\n",
        "\n",
        "class ResidualBlock (torch.nn.Module):\n",
        "  def __init__( self):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    self.block = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(64, 64, 3, padding=1),\n",
        "        torch.nn.BatchNorm2d(64),\n",
        "        torch.nn.PReLU(),\n",
        "        torch.nn.Conv2d(64, 64, 3, padding=1),\n",
        "        torch.nn.BatchNorm2d(64),\n",
        "    )\n",
        "\n",
        "  def forward(self, x ):\n",
        "    return self.block(x) + x \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYFT-UojGC8Q"
      },
      "source": [
        "class discriminator (torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(discriminator, self).__init__()\n",
        "    self.Conv1 = torch.nn.Conv2d(3, 64, 3)\n",
        "    self.Conv2 = torch.nn.Conv2d(64, 64, 3, stride=2)\n",
        "    self.BatchNorm2 = torch.nn.BatchNorm2d(num_features=64)\n",
        "    self.Conv3 = torch.nn.Conv2d(64, 128, 3)\n",
        "    self.BatchNorm3 = torch.nn.BatchNorm2d(num_features=128)\n",
        "    self.Conv4 = torch.nn.Conv2d(128, 128, 3, 2)\n",
        "    self.BatchNorm4 = torch.nn.BatchNorm2d(num_features=128)\n",
        "    self.Conv5 = torch.nn.Conv2d(128, 256, kernel_size=3)\n",
        "    self.BatchNorm5 = torch.nn.BatchNorm2d(num_features=256)\n",
        "    self.Conv6 = torch.nn.Conv2d(256, 256, kernel_size=3,stride=2)\n",
        "    self.BatchNorm6 = torch.nn.BatchNorm2d(num_features=256)\n",
        "    self.Conv7 = torch.nn.Conv2d(256, 512, kernel_size=3)\n",
        "    self.BatchNorm7 = torch.nn.BatchNorm2d(num_features=512)\n",
        "    self.Conv8 = torch.nn.Conv2d(512, 512, kernel_size=3, stride=2)\n",
        "    self.BatchNorm8 = torch.nn.BatchNorm2d(num_features=512)\n",
        "\n",
        "    self.hidden = torch.nn.Conv2d(512, 1024,kernel_size=1,  stride=3)\n",
        "    self.final_classifier = torch.nn.Conv2d(1024, 1, kernel_size=1)\n",
        "    self.leakyReLU = torch.nn.LeakyReLU(negative_slope=0.2)\n",
        "    self.dropout = torch.nn.Dropout(p=0.2)\n",
        "\n",
        "\n",
        "  def forward(self, x ):\n",
        "    x = self.leakyReLU(self.Conv1(x))\n",
        "    x = self.leakyReLU(self.BatchNorm2(self.Conv2(x)))\n",
        "    x = self.leakyReLU(self.BatchNorm3(self.Conv3(x)))\n",
        "    x = self.dropout(x)\n",
        "    x = self.leakyReLU(self.BatchNorm4(self.Conv4(x)))\n",
        "    x = self.leakyReLU(self.BatchNorm5(self.Conv5(x)))\n",
        "    x = self.dropout(x)\n",
        "    x = self.leakyReLU(self.BatchNorm6(self.Conv6(x)))\n",
        "    x = self.leakyReLU(self.BatchNorm7(self.Conv7(x)))\n",
        "    x = self.leakyReLU(self.BatchNorm8(self.Conv8(x)))\n",
        "    x = self.dropout(x)\n",
        "    x = self.leakyReLU(self.hidden(x))\n",
        "    x = self.final_classifier(x)\n",
        "    return torch.sigmoid(x).view(x.shape[0], -1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlzccsRnRqgL"
      },
      "source": [
        "class vgg_loss ():\n",
        "\n",
        "  def __init__(self, device):\n",
        "    super(vgg_loss, self).__init__()\n",
        "    vgg = torchvision.models.vgg19(pretrained=True)\n",
        "    vgg = vgg.features\n",
        "\n",
        "    # Freeze all vgg layers \n",
        "    for param in vgg.parameters():\n",
        "      param.requires_grad = False \n",
        "    \n",
        "    self.vgg = vgg[:27].to(device) \n",
        "    self.MSE = torch.nn.MSELoss()\n",
        "\n",
        "  def __call__(self, input ):\n",
        "    return self.vgg(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwxNZygOXTj6"
      },
      "source": [
        "# DATA LOADERS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySLjI6M1zKQK"
      },
      "source": [
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo)\n",
        "    return dict "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOL2ESHyynZ-"
      },
      "source": [
        "def get_images_x64(filename):\n",
        "  d = unpickle(filename)\n",
        "  x = d['data']\n",
        "  x = np.dstack((x[:, :4096], x[:, 4096:8192], x[:, 8192:]))\n",
        "  x = x.reshape((x.shape[0], 64, 64, 3))\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jyRA29KEe0p"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/CSC413/x64/'\n",
        "\n",
        "class SRDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, main_dir):\n",
        "    self.transform_HR = torchvision.transforms.Compose(\n",
        "                            [torchvision.transforms.ToTensor(), \n",
        "                              torchvision.transforms.RandomCrop(96, pad_if_needed=True, padding_mode=\"reflect\")])\n",
        "\n",
        "    self.transform_LR = torchvision.transforms.Compose([torchvision.transforms.Resize((24,24), \n",
        "                        interpolation=torchvision.transforms.InterpolationMode.BICUBIC)])\n",
        "\n",
        "    matches = []\n",
        "    for root, dirnames, filenames in os.walk(main_dir):\n",
        "      for filename in fnmatch.filter(filenames, '*.jpg'):\n",
        "        matches.append(os.path.join(root, filename))\n",
        "\n",
        "    print(\"Number of images found in \" + main_dir + \":\", end=\"\")\n",
        "    print(len(matches))\n",
        "    self.matches = np.array(matches) \n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.matches)\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    path = self.matches[idx]\n",
        "    image = Image.open(path).convert(\"RGB\")\n",
        "    HR = self.transform_HR(image)\n",
        "    LR = self.transform_LR(HR)\n",
        "    return {'HR': HR, 'LR': LR}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3SCmhEjXmlN"
      },
      "source": [
        "# TRAINING CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7X1MNMbYpCk"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfjpXNYyAgcY"
      },
      "source": [
        "def gan_checkpoint(path, G, D):\n",
        "    \"\"\"Saves the parameters of the generator G and discriminator D.\n",
        "    \"\"\"\n",
        "    G_path = os.path.join(path, 'G.pkl')\n",
        "    D_path = os.path.join(path, 'D.pkl')\n",
        "    torch.save(G.state_dict(), G_path)\n",
        "    torch.save(D.state_dict(), D_path)\n",
        "\n",
        "def load_checkpoint(opts):\n",
        "    \"\"\"Loads the generator and discriminator models from checkpoints.\n",
        "    \"\"\"\n",
        "    G_path = os.path.join(opts.load, 'G.pkl')\n",
        "    D_path = os.path.join(opts.load, 'D.pkl')\n",
        "\n",
        "    G = generator()\n",
        "    D = discriminator()\n",
        "\n",
        "    G.load_state_dict(torch.load(G_path, map_location=lambda storage, loc: storage))\n",
        "    D.load_state_dict(torch.load(D_path, map_location=lambda storage, loc: storage))\n",
        "\n",
        "    G.to(opts.device)\n",
        "\n",
        "    return G, D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOGoKyuSACfx"
      },
      "source": [
        "\"\"\"\n",
        "CREDITS: CSC413 PA4 DCGAN\n",
        "\"\"\"\n",
        "\n",
        "def train(opts):\n",
        "    \"\"\"Runs the training loop.\n",
        "        * Saves checkpoint every opts.checkpoint_every iterations\n",
        "        * Saves generated samples every opts.sample_every iterations\n",
        "    \"\"\"\n",
        "    # Create generators and discriminators\n",
        "    G = generator().to(opts.device)\n",
        "    D = discriminator().to(opts.device)\n",
        "\n",
        "    g_params = G.parameters()  # Get generator parameters\n",
        "    d_params = D.parameters()  # Get discriminator parameters\n",
        "\n",
        "    # Create optimizers for the generators and discriminators\n",
        "    g_optimizer = torch.optim.Adam(g_params, opts.lr, [opts.beta1, opts.beta2])\n",
        "    d_optimizer = torch.optim.Adam(d_params, opts.lr, [opts.beta1, opts.beta2])\n",
        "\n",
        "    print(\"loading scrape ... \")\n",
        "    train_set_scrape = SRDataset(\"/content/flickr/\")\n",
        "    train_loader_scrape = torch.utils.data.DataLoader(train_set_scrape, opts.batch_size,\n",
        "                              shuffle=True, num_workers=opts.num_workers)\n",
        "\n",
        "    print(\"loading flickr ... \")\n",
        "    train_set_flickr = SRDataset(\"/content/scrape/\")\n",
        "    train_loader_flickr = torch.utils.data.DataLoader(train_set_flickr, opts.batch_size,\n",
        "                              shuffle=True, num_workers=opts.num_workers)\n",
        "\n",
        "    # start with the scraped images \n",
        "    train_iter = iter(train_loader_scrape)\n",
        "    iter_per_epoch = len(train_iter)\n",
        "    is_scrape = True \n",
        "\n",
        "    total_train_iters = opts.train_iters\n",
        " \n",
        "    # adversarial_loss = torch.nn.BCEWithLogitsLoss()\n",
        "    gp_weight = 1\n",
        "\n",
        "    losses ={}\n",
        "    losses['iteration'] = []\n",
        "    losses['D_loss'] = []\n",
        "    losses['G_loss'] = []\n",
        "\n",
        "\n",
        "    VGG = vgg_loss(opts.device)\n",
        "    MSE = torch.nn.MSELoss()\n",
        "    BCE = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "    # Quick Testing \n",
        "    data_transforms = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(64),\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    image_name = \"/content/drive/MyDrive/CSC413/LR_Test.jpg\"\n",
        "    og_image = Image.open(image_name)\n",
        "    image = data_transforms(og_image).float()\n",
        "    image = torch.tensor(image, requires_grad=True)\n",
        "    image = image.unsqueeze(0).to(opts.device)\n",
        "\n",
        "\n",
        "    try:\n",
        "        for iteration in range(1, opts.train_iters + 1):\n",
        "\n",
        "            G.train()\n",
        "            g_optimizer.zero_grad()\n",
        "\n",
        "            # Reset data_iter for each epoch\n",
        "            if iteration % iter_per_epoch == 0:\n",
        "              if is_scrape: \n",
        "                train_iter = iter(train_loader_flickr)\n",
        "                iter_per_epoch = len(train_iter)\n",
        "              else: \n",
        "                train_iter = iter(train_loader_scrape)\n",
        "                iter_per_epoch = len(train_iter)\n",
        "              is_scrape = !is_scrape \n",
        "              \n",
        "\n",
        "            next = train_iter.next()\n",
        "            HR =  next['HR']\n",
        "            LR = next['LR']\n",
        "            HR = HR.to(opts.device)\n",
        "            LR = LR.to(opts.device)\n",
        "\n",
        "            # ------------------------ DISCRIMINATOR LOSS ---------------------\n",
        "\n",
        "\n",
        "            d_optimizer.zero_grad()\n",
        "\n",
        "            HRE = G(LR)\n",
        "            logits_HRE = D(HRE)\n",
        "            logits_HR = D(HR)\n",
        "            \n",
        "            D_1 = torch.mean(logits_HR)\n",
        "            D_2 = torch.mean(logits_HRE)                \n",
        "            D_loss = 1 - D_1 + D_2 \n",
        "\n",
        "            if D_loss > 0.001: \n",
        "              D_loss.backward(retain_graph=True)\n",
        "              d_optimizer.step()\n",
        "\n",
        "\n",
        "            # ------------------------ GENERATOR LOSS -----------------------\n",
        "\n",
        "            g_optimizer.zero_grad()\n",
        "\n",
        "            HRE = G(LR)\n",
        "            logits_HRE = D(HRE)\n",
        "            vgg_HR = VGG(HR)\n",
        "            vgg_HRE = VGG(HRE)\n",
        "\n",
        "            G_1 = torch.mean(1 - logits_HRE)\n",
        "            G_VGG = MSE(vgg_HRE, vgg_HR)\n",
        "            G_MSE = MSE(HRE, HR)\n",
        "            G_loss = G_MSE + 0.006 * G_VGG + 0.001 * G_1 \n",
        "\n",
        "            G_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "            # ------------------------  CHECKPOINTS & SAMPLING -------------------\n",
        "\n",
        "            if iteration % opts.log_step == 0:\n",
        "                losses['iteration'].append(iteration)\n",
        "                losses['D_loss'].append(D_loss.item())\n",
        "                losses['G_loss'].append(G_loss.item())\n",
        "                print('Iteration [{:4d}/{:4d}] | D_loss: {:6.4f} |  G_loss: {:6.4f}'.format(\n",
        "                    iteration, total_train_iters, D_loss.item(), G_loss.item()))\n",
        "\n",
        "            # Save the model parameters\n",
        "            if iteration % opts.checkpoint_every == 0:\n",
        "                checkpoint = opts.checkpoint\n",
        "\n",
        "                dir = checkpoint + str(iteration)\n",
        "                if os.path.exists(dir):\n",
        "                  shutil.rmtree(dir)\n",
        "                os.mkdir(dir)\n",
        "                gan_checkpoint(dir, G, D)\n",
        "\n",
        "                G.eval()\n",
        "\n",
        "                image_est = (G(image).clone().detach().cpu().numpy())\n",
        "                image_est = np.squeeze(image_est, axis=0)\n",
        "                image_est = np.transpose(image_est, (1,2,0) )\n",
        "\n",
        "                f, axarr = plt.subplots(1,2)\n",
        "                axarr[0].imshow(og_image)\n",
        "                axarr[1].imshow(image_est)\n",
        "                f.savefig(dir + '/sample.png', bbox_inches='tight')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('Exiting early from training.')\n",
        "        return G, D\n",
        "\n",
        "    return G, D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qPEimgKYsD_"
      },
      "source": [
        "## Hyperparameters and running loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYAZaLJsY0J5"
      },
      "source": [
        "opts = AttrDict()\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "args_dict = {\n",
        "    'checkpoint': \"/content/drive/MyDrive/CSC413/checkpoints/\",\n",
        "    'lr': 0.00005,\n",
        "    'beta1':0.9,\n",
        "    'beta2':0.999,\n",
        "    'batch_size': 32,\n",
        "    'device': device, \n",
        "    'epochs': 12,\n",
        "    'num_workers': 4,\n",
        "    'resume': False,\n",
        "    'log_step': 100, \n",
        "    'checkpoint_every':1000,\n",
        "    'train_iters':200000,\n",
        "    'batch' : 'train_data_batch_1'\n",
        "}\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "opts.update(args_dict)\n",
        "train(opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mf2Xg8_4bJI"
      },
      "source": [
        "# TEST IMAGE CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8Tc7bepAYWL"
      },
      "source": [
        "import cv2\n",
        "\n",
        "def torch_to_saveable_image(image_est):\n",
        "  image_est = image_est.cpu().clone().detach().numpy()\n",
        "  image_est = np.transpose(image_est, (1,2,0))\n",
        "  image_est = np.clip(image_est, a_min=0, a_max=1)\n",
        "  print(np.min(image_est))\n",
        "  print(np.max(image_est))\n",
        "\n",
        "  image_est = cv2.normalize(image_est, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
        "  image_est = cv2.cvtColor(image_est, cv2.COLOR_RGB2BGR)\n",
        "  return image_est\n",
        "\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "first_path = \"/content/drive/MyDrive/CSC413/final/x64.pkl\"\n",
        "Gx64 = generator()\n",
        "Gx64.load_state_dict(torch.load(first_path, map_location=lambda storage, loc: storage))\n",
        "\n",
        "second_path = \"/content/drive/MyDrive/CSC413/final/x128.pkl\"\n",
        "Gx128 = generator()\n",
        "Gx128.load_state_dict(torch.load(second_path, map_location=lambda storage, loc: storage))\n",
        "\n",
        "Gx128.to(device)\n",
        "Gx64.to(device)\n",
        "\n",
        "\n",
        "data_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Resize((64,64))\n",
        "])\n",
        "\n",
        "\n",
        "filetype = \".png\"\n",
        "directory = \"/content/drive/MyDrive/CSC413/set14/\"\n",
        "\n",
        "from os import walk\n",
        "\n",
        "_, _, filenames = next(walk(directory))\n",
        "\n",
        "filenames = [\"monarch\"]\n",
        "for name in filenames:\n",
        "  \n",
        "  filename = os.path.splitext(name)[0]\n",
        "  image_name = directory + filename  + filetype\n",
        "\n",
        "\n",
        "  og_image = Image.open(image_name).convert(\"RGB\")\n",
        "  width, height = og_image.size\n",
        "\n",
        "  data_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Resize((height // 4 ,width // 4 ))\n",
        "  ])\n",
        "  \n",
        "\n",
        "  image = data_transforms(og_image).float()\n",
        "  image = torch.tensor(image, requires_grad=False)\n",
        "  image = image.unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "  image_est = Gx128(image).squeeze(0)\n",
        "\n",
        "\n",
        "  bicubic = torchvision.transforms.Resize((height,width))\n",
        "  image =  image.squeeze(0)\n",
        "  bicubic = bicubic(image)\n",
        "  bicubic = torch_to_saveable_image(bicubic)\n",
        "\n",
        "\n",
        "  image_est = torch_to_saveable_image(image_est)\n",
        "  cv2.imwrite(directory + filename + \"_GAN.png\", image_est)\n",
        "  cv2.imwrite(directory + filename + \"_Bicubic.png\", bicubic)\n",
        "\n",
        "  # image_est = Gx128(image).squeeze(0)\n",
        "  # image_est = torch_to_saveable_image(image_est)\n",
        "  # cv2.imwrite(directory + filename + \"_x128.png\", image_est)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}